<!DOCTYPE html><html lang="ja" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="卒研の経緯" /><meta property="og:locale" content="ja" /><meta name="description" content="NLP2023 で発表した『自己注意機構における注意の集中が相対位置に依存する仕組み (pdf)（以後、当研究）』は、 いろいろと試行錯誤した末の着地点だけを述べていて、そういえばそこに至った経緯に触れていなかったので、 卒研と学会を懐かしみながら書きました。（26 min Read は草。）" /><meta property="og:description" content="NLP2023 で発表した『自己注意機構における注意の集中が相対位置に依存する仕組み (pdf)（以後、当研究）』は、 いろいろと試行錯誤した末の着地点だけを述べていて、そういえばそこに至った経緯に触れていなかったので、 卒研と学会を懐かしみながら書きました。（26 min Read は草。）" /><link rel="canonical" href="https://yuji96.github.io/posts/NLP2023-paper-history/" /><meta property="og:url" content="https://yuji96.github.io/posts/NLP2023-paper-history/" /><meta property="og:site_name" content="yuji96" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-04-06T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="卒研の経緯" /><meta name="twitter:site" content="@Mt_B00Ks" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-05-03T17:14:31+09:00","datePublished":"2023-04-06T00:00:00+09:00","description":"NLP2023 で発表した『自己注意機構における注意の集中が相対位置に依存する仕組み (pdf)（以後、当研究）』は、 いろいろと試行錯誤した末の着地点だけを述べていて、そういえばそこに至った経緯に触れていなかったので、 卒研と学会を懐かしみながら書きました。（26 min Read は草。）","headline":"卒研の経緯","mainEntityOfPage":{"@type":"WebPage","@id":"https://yuji96.github.io/posts/NLP2023-paper-history/"},"url":"https://yuji96.github.io/posts/NLP2023-paper-history/"}</script><title>卒研の経緯 | yuji96</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="yuji96"><meta name="application-name" content="yuji96"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/favicons/avatar.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">yuji96</a></div><div class="site-subtitle font-italic">Re: It is a too yummy jam!</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a><li class="nav-item active"> <a href="/blog/" class="nav-link"> <i class="fa-fw fas fa-pen ml-xl-3 mr-xl-3 unloaded"></i> <span>BLOG</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/yuji96" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/Mt_B00Ks" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span><a href="/blog/">Blog</a></span> <span>卒研の経緯</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>卒研の経緯</h1><div class="post-meta text-muted"><div class="d-flex"><div> <span> Posted <em class="timeago" date="2023-04-06 00:00:00 +0900" data-toggle="tooltip" data-placement="bottom" title="Thu, Apr 6, 2023, 12:00 AM +0900" >Apr 6</em> </span> <span> Updated <em class="timeago" date="2023-05-03 17:14:31 +0900 " data-toggle="tooltip" data-placement="bottom" title="Wed, May 3, 2023, 5:14 PM +0900" >May 3</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="5055 words"> <em>28 min</em> read</span></div></div></div><div class="post-content"><p>NLP2023 で発表した『自己注意機構における注意の集中が相対位置に依存する仕組み (<a href="https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/C3-3">pdf</a>)（以後、当研究）』は、 いろいろと試行錯誤した末の着地点だけを述べていて、そういえばそこに至った経緯に触れていなかったので、 卒研と学会を懐かしみながら書きました。（26 min Read は草。）</p><p>自分の研究”だけ”に向き合っていると気づかなかったが、自分の分析方針はどうやら異質らしい。 （自覚している範囲だと）下の 3 点が異質に感じる。</p><ul><li>そもそも軸が違う<li>文章表現の周波数領域について分析している<li>データではなくパラメータに対して特異値分解をしている<li>etc.</ul><p>このそれぞれについて（etc. も含めて）4 セクションを分けて「なぜそうしたのか」を振り返る。</p><h2 id="そもそも軸が違う">そもそも軸が違う<a href="#そもそも軸が違う" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>埋め込み表現の分野をざっくりと言い表すと、入力や出力やモデル内部から得られる埋め込み行列 $X$ の分析をしている。 本記事では、この $X$ を下図のように定義する。</p><p><img data-src="/assets/img/posts/NLP2023-paper-history/matrix-1.png" width="300px" data-proofer-ignore></p><details> <summary>脱線</summary><p>このブログの fork 元の<a href="https://chirpy.cotes.page/posts/text-and-typography/#float-to-left">デモ</a>を久しぶりに見たら、画像を回り込んで文章が書ける機能が追加されていた。反映したいけど merge しようとしたら conflict 大量発生して奇声あげそうなので保留…</p></details><p>例えば、<code class="language-plaintext highlighter-rouge">["I", "will", "be", "back", "!"]</code> というトークン列を埋め込み行列 $X$ で考えると、<code class="language-plaintext highlighter-rouge">"be"</code> の埋め込み表現は $X$ の 3 行目に対応する。 一般的な研究では、単語に対応する埋め込みである各行について分析が行われている。</p><p><img data-src="/assets/img/posts/NLP2023-paper-history/matrix-2.png" width="300px" data-proofer-ignore></p><p>しかし、当研究は位置に興味があったので、行分解して文をバラバラの単語にするのではなく列で分解した。</p><p><img data-src="/assets/img/posts/NLP2023-paper-history/matrix-3.png" width="300px" data-proofer-ignore></p><p>これが一般的な方針と異なる理由だ。（正直、これはそこまで変なことをしているわけではないとは思う。）</p><h2 id="文章表現の周波数領域について分析している">文章表現の周波数領域について分析している<a href="#文章表現の周波数領域について分析している" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>この見出しだけ見ると変態の所業に感じる。 ただし、文章が時系列データだと抽象的に考えると、これも別にそこまで変態ではないはず。</p><p>時系列データとは内容だけでなくその順番にも意味があるデータのことを指す。 時系列データであるか否かは、データをシャッフルしていいかを考えると簡単に判定できる。 例えば、音楽などはシャッフルしたらデータの意味が崩壊してしまう。</p><p>では、文章はどうか。音楽のドレミと異なり、単語には重要度に差があるので、 bag-of-words のように順番を無視しても推論できちゃったりするが、 高精度を出すには単語の順序、つまり、文脈を捉える必要が出てくる。 したがって、文章は時系列データの一種である。</p><p>すると、音楽や音声などを扱う信号処理分野で日常的に行われるフーリエ変換を埋め込み行列 $X$ の列方向に適用するのも、 変わっているかも知れないが荒唐無稽ではないだろう。</p><p>（学会発表で振幅スペクトルの話の導入に、この辺のお気持ちを述べるべきだったと反省。）</p><h2 id="データではなくパラメータに対して特異値分解をしている">データではなくパラメータに対して特異値分解をしている<a href="#データではなくパラメータに対して特異値分解をしている" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>特異値分解（SVD）は主成分分析（PCA）とほぼ同じようなもんらしいので<sup id="fnref:qiita" role="doc-noteref"><a href="#fn:qiita" class="footnote" rel="footnote">1</a></sup>、 見出しを「データではなくパラメータに対して PCA をしている」に変えてみる。 すると、一気に変態な見出しになった。</p><p>普通、 PCA といえば下の例のように、<strong>データ</strong> に対して行われる。</p><ul><li>5 教科のテストの点数を PCA すると、理系っぽさと解釈できる主成分ベクトルが得られた。<ul><li>多分、<code class="language-plaintext highlighter-rouge">数学 + 理科 - 国語 - 社会</code> みたいな感じのベクトルになると思う。</ul><li>word2vec の単語埋め込みを PCA すると、第 1 主成分が頻度、第 2 主成分が品詞とそれぞれ解釈できそうなベクトルが得られた。</ul><p>しかし、今回の対象はパラメータだから「？」となってしまう。 このセクションの経緯を説明するのが一番難しいのでいくつかのサブセクションに分ける。</p><h3 id="初期目標-中間層から位置埋め込み由来の成分を取り出す">初期目標: 中間層から位置埋め込み由来の成分を取り出す<a href="#初期目標-中間層から位置埋め込み由来の成分を取り出す" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>まず、最初はもちろん（パラメータではなくデータである）埋め込み行列 $X$ に対して PCA をして、位置表現のような主成分を得ようとした。 他にも、音源分離に使われる独立成分分析（ICA）も試したりした（<a href="https://www.kecl.ntt.co.jp/icl/signal/sawada/mypaper/subspace2010rev.pdf">参考</a>）<sup id="fnref:ica" role="doc-noteref"><a href="#fn:ica" class="footnote" rel="footnote">2</a></sup><sup id="fnref:ica2" role="doc-noteref"><a href="#fn:ica2" class="footnote" rel="footnote">3</a></sup>。</p><p>このへんは ‘23 年度の夏休み前にしていたのであまり覚えていないが、別に PCA でも入力層付近ならそれっぽい成分を抽出することはできていた。 ただ、あくまで「それっぽさ」までしか得られないので、胸張って「抽出できました！卒研終了！！」みたいな雰囲気ではなかった<sup id="fnref:posa" role="doc-noteref"><a href="#fn:posa" class="footnote" rel="footnote">4</a></sup>。</p><h3 id="最終目標-位置埋め込み由来の成分が文脈に従った推論に寄与することを示す">最終目標: 位置埋め込み由来の成分が文脈に従った推論に寄与することを示す<a href="#最終目標-位置埋め込み由来の成分が文脈に従った推論に寄与することを示す" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>おそらくこのもやもやした気持ちの原因は、<strong>PCA を使って初期目標を達成したとしても最終目標は 1mm も達成できない</strong>ことに薄々気づいていたからだと思う<sup id="fnref:moya" role="doc-noteref"><a href="#fn:moya" class="footnote" rel="footnote">5</a></sup>。</p><p>仮に、PCA で位置埋め込みに由来する成分をほぼ完璧に抽出できたとする。 しかし、その結果は PCA が文脈理解に必要な成分を抽出できることを示しただけで、文脈を捉える役目の自己注意機構がそれをできるかとは全く関係ない。</p><h3 id="静と動">静と動<a href="#静と動" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>（このセクションを書いていて、自分ってこういうことに興味があったんだということに気づかされた。）</p><p>この研究で示したいのは「埋め込みに〇〇という性質が存在する」という<strong>状態</strong>ではなく、「モデルが〇〇できる」という<strong>動作</strong>の方だった。 すると、分析対象とすべきなのは埋め込み行列 $X$ ではなくパラメータの方ではないか。</p><p>PCA は単純に入力 $X$ を直交変換して出力 $Y$ を計算する。（つまり、基底の取り替えにより視点を変えるだけで、データ $X$ を崩すようなことはしない。）すなわち、パラメータを直交行列 $U$ とおくと</p>\[Y = XU \tag{a}\]<p>のようにとても単純に書ける。この解釈性の良さのおかげで PCA は重宝されている。</p><p>あれなんかこの形見たことあるな。</p>\[Q = XW^Q,~K=XW^K \tag{b}\]<p>クエリとキーですね。もしかして、PCA とか ICA とか面倒なことしなくてもクエリとキーをそのまま可視化すると実は面白い形をしてたりして…？<sup id="fnref:viz" role="doc-noteref"><a href="#fn:viz" class="footnote" rel="footnote">6</a></sup></p><p>これがマジでした（位置に関して推論するために位置に関する成分を抽出する必要があるので納得はできる）。 クエリとキーにバンドパスフィルタをかけてバイアスやノイズっぽいものを除くとよりきれいな形が見えてくる。 このノイズはおそらく単語埋め込み由来の成分だと考えられる<sup id="fnref:noise" role="doc-noteref"><a href="#fn:noise" class="footnote" rel="footnote">7</a></sup>。</p><p>つまり、フィルタリング前は各次元に位置表現と単語表現が混在している。 ならば、基底の取り替えれば位置表現だけが抽出できるのではないか。</p><details> <summary>表現が混在するとは</summary><p>NLP における埋め込み表現に関わらず、深層学習全般のニューラル表現分析でもこのような話は出てくる。 例えば、画像分類モデルのある層において、5 個のニューロンが <code class="language-plaintext highlighter-rouge">形, 色, 明るさ</code> という 3 つの特徴を学習していたとする。 じゃあ、1 番目のニューロンが <code class="language-plaintext highlighter-rouge">形</code> を捉えていて、2 番目のニューロンが <code class="language-plaintext highlighter-rouge">色</code> を捉えていて、 なんてことはなく複数の特徴はいくつかのニューロンに散らばっている。</p><p>そこで、1 つのニューロンが 1 つの特徴を推論しているかのようにうまく表現を整理できれば、解釈性が大きく向上する。 表現分析の目的は解釈性を向上させることなので、整理のためにエグい手法を使うことはおそらく少なく、 分かりやすい単純な直交変換などが好まれる。</p></details><h3 id="特異値分解svdの導入">特異値分解（SVD）の導入<a href="#特異値分解svdの導入" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>論文にも記載したが、クエリとキーの積 $QK^T$ を計算するときに $W^Q(W^K)^T$ を計算するため、 パラメータ行列は 2 つあるように見えて実は 1 つの行列を分解したものである。もし、</p>\[\begin{aligned} W^Q &amp;\leftarrow W^Q(W^K)^T \\ W^K &amp;\leftarrow I \end{aligned}\]<p>のようにパラメータを置き換えても $QK^T$ は全く変わらない。 つまり、クエリとキーはパラメータが混ざり合っていて、はっきりとした境界が存在しないため、お互いが独立した概念ではない。 （例えば、クエリ $Q$ を作る重要な成分が $W^K$ にあり、その逆もあるかもしれない。） そのため、式 (a) と式 (b) は形は似ているが、$W^Q,~W^K$ 自体は特徴を抽出しているとは言えない。</p><p>ここでの目標は</p>\[Q = XU^Q,~K=XU^K\]<p>における、PCA のパラメータ行列のような $U^Q,~U^K$ を得ることである。 そして、PCA と同じく $U^Q,~U^K$ が直交行列として得られたらより嬉しい。</p><p>ここで、SVD を用いると</p>\[W^Q(W^K)^T = U^Q S (U^K)^T\]<p>とパラメータが分解されて直交行列である左右特異ベクトルが得られる。 この $U^Q,~U^K$ を $X$ に書けたものを可視化すると欲しかった表現が得られた。 SVD でなぜうまくいくのかははっきりとは分からない。 まあ、PCA や t-sne で表現が分かりやすくなることもあればそうでないこともあるのでそんなもんなのだろう。</p><h3 id="セクションまとめ">セクションまとめ<a href="#セクションまとめ" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>このセクションのはじめに「データではなくパラメータに対して PCA をしている」という発言をしたが、 これは自分のお気持ちとは全く異なる（数式ではそう見えちゃうけど）。</p><p>やりたかったことは、一般的なケースと同じく、データ $X$ に対して基底変換をして解釈しやすい表現を得ることである。 そのための変換行列 $U$ は <a href="#最終目標-位置埋め込み由来の成分が文脈に従った推論に寄与することを示す">§最終目標</a> でも触れた通り、 パラメータ $W$ から得たかった。そこで $W$ から $U$ を得る過程で特異値分解を用いた。</p><p>つまり、パラメータを基底変換することで、重要なパラメータの軸やその寄与度が欲しいというお気持ちはなく、 普通に混じった表現を特徴ごとに分けたくて、その過程で SVD が有効だった。</p><p>そもそも $W^Q(W^K)$ という<strong>混ざったパラメータ</strong>が Transformer 以外でほぼ見かけないので、 パラメータを整理するという発想も受け入れ難いのかもしれない。</p><h2 id="etc">etc.<a href="#etc" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="クエリとキーは個別に考えられないと言ったそばから分解するのはなぜ">クエリとキーは個別に考えられないと言ったそばから分解するのはなぜ<a href="#クエリとキーは個別に考えられないと言ったそばから分解するのはなぜ" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>一言でいうと、クエリとキーを個別に考えたかったから（考えられない ≠ 考えてはいけない）。クエリとキーの積を一つの塊として扱うと、 ほぼほぼアテンション重み $A$ と同じ行列になってしまう<sup id="fnref:diff" role="doc-noteref"><a href="#fn:diff" class="footnote" rel="footnote">8</a></sup>。</p><p>自分の興味は「このヘッドでは位置を見てるね」「このヘッドでは係り受けを推論しているね」という結果を知ることではなく、「どうやって位置を見ているんだろう」「どうやって係り先を特定できるのだろう」という操作の方にある。</p><p>この立場だと、アテンション重み $A$ はパラメータが色々操作した結果として得られた行列でしかない。 なので、そうなった経緯を知るためには分解したくなる。</p><ol><li>入力: 埋め込み行列 $X$<li>途中経過: クエリ $Q$, キー $K$ （← ここが見たい）<li>観察結果: アテンション重み $A$</ol><h3 id="埋め込み層だけでなく各層でも直に位置埋め込みを入れたほうがいい">埋め込み層だけでなく各層でも直に位置埋め込みを入れたほうがいい？<a href="#埋め込み層だけでなく各層でも直に位置埋め込みを入れたほうがいい" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><del>残差接続（Residual Connection）があるので、最終層にも位置埋め込みを直で入力しているとみなせる（多分）。</del></p>\[\begin{aligned} &amp;\xcancel{X = W + P }\\ &amp;\xcancel{layer_{12}( \cdots (layer_2(layer_1(X) + X) + X) \cdots ) + X} \end{aligned}\]<p>訂正：こんなに単純な話ではない。</p><p>1 層目の Attention の出力 $X$ と埋め込み層の出力 $W+P$ （単語埋め込み $W$ と位置埋め込み $P$ の和）に対する LayerNorm は、位置埋め込み $P$ とその他 $X+W$ の和に適用していると見れる。 ここで、その他を無視すると</p>\[LayerNorm(* + P) = * + SPL\]<p>と書ける。 ただし、$S$ と $L$ はスケールバラメータで対角行列。バイアスは $*$ に吸収させている。 つまり、sub-layer を抜けるごとに位置埋め込みの両側の対角行列が増えていくので、$n+1$ 層目の入力は</p><p>$layer_{n+1}(* + S_{n}^fS_{n}^a \cdots S_{1}^fS_{1}^a \cdot P \cdot L_{1}^aL_{1}^f \cdots L_{n}^aL_{n}^f )$</p><p>みたいな感じになっている（のかな？）。 これが正しければ、対角行列の積は対角行列だから結局は最初と同じ</p><p>$layer_{n+1}(* + SPL )$</p><p>と書ける。</p><p>訂正前と大きく違うのは $S~(= \text{diag}(\text{Std}[token_i]))$ が左から掛かってしまうこと。 絶対位置埋め込みが周期的なときに、左から行列がかかると、きれいな波形が がったがたになりそう。 つまり、$S$ によっては位置埋め込みが壊れて上位層には伝わらなそう。</p><p>（訂正部分終了）</p><p>なので、モデルの分析をしたときに後層では位置埋め込み由来の成分が目立たない原因は、 入力層から上手く伝わっていないのではなく、モデルが捨てていると思われる。</p><p>「付き合ってください」って言われた数秒後に「”合” という漢字は 3 文字目だったな」と思うことはないだろう（言われたこと無いから知らんが）。このように後層に行くにつれて位置情報は徐々に不要になり、意味的推論に移行すると考えられる。</p><h2 id="編集後記">編集後記<a href="#編集後記" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p><a href="/posts/attention-for-me/">自分なりの Self Attention の解釈</a> という記事は書き始めから 2 ヶ月経ってるのに 1/3 くらいしか書いてないという怠慢なことをしているので、今回はそうならないように 1 日で一気に書ききった。 脳内をかなりさらけ出したので恥ずかしさや怖さを感じている。</p><hr /><div class="footnotes" role="doc-endnotes"><ol><li id="fn:qiita" role="doc-endnote"><p><a href="https://qiita.com/horiem/items/71380db4b659fb9307b4">https://qiita.com/horiem/items/71380db4b659fb9307b4</a> <a href="#fnref:qiita" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:ica" role="doc-endnote"><p>$n$ 個の楽器からなるオーケストラを $d~(\ge n)$ 個のマイクで収録すると $d$ 個の音源ができる。その音源に対して ICA を行うと、楽器ごとの $n$ 個の音源に分離できる（うまくいけば）。 <a href="#fnref:ica" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:ica2" role="doc-endnote"><p>埋め込み表現だと、$n$ 通りの何らかの価値のある表現を $d$ 次元空間から上手く取り出すという風に言い換えられる。ただし、$n$ は未知なので 1~20 くらいの値で色々試すことになる。 <a href="#fnref:ica2" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:posa" role="doc-endnote"><p>実際、PCA はそれっぽい軸を得るための手法なので、PCA を使う以上避けては通れない。 <a href="#fnref:posa" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:moya" role="doc-endnote"><p>当時はこの言語化できていなかった。 <a href="#fnref:moya" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:viz" role="doc-endnote"><p>huggingface を使っている場合、$X$ は <code class="language-plaintext highlighter-rouge">output_hidden_states=True</code> とすれば取得できるが、$Q$ や $K$ はちょっとした実装をしないと得られないので、 そのまま見たことある人は実はものすごく少ないのではないか。 <a href="#fnref:viz" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:noise" role="doc-endnote"><p>どんな文章でもトークンの位置 <code class="language-plaintext highlighter-rouge">[1, 2, 3, ...]</code> はもちろん変わらない（当たり前過ぎて逆に変に聞こえるかも）。 しかし、<code class="language-plaintext highlighter-rouge">happy</code> という単語は文によって 5 番目に現れたり 100 番目に現れたりするので、行列 $X$ の列方向に分析するときはほぼノイズにしか見えない。 <a href="#fnref:noise" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:diff" role="doc-endnote"><p>scale や softmax の有無に違いはあるが、どちらも大小関係は変えないので、attention が当たるトークン関係は変わらない。 <a href="#fnref:diff" class="reversefootnote" role="doc-backlink">&#8617;</a></p></ol></div></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/article/'>article</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/nlp/" class="post-tag no-text-decoration" >NLP</a> <a href="/tags/math/" class="post-tag no-text-decoration" >math</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"></div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=卒研の経緯 - yuji96&url=https://yuji96.github.io/posts/NLP2023-paper-history/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=卒研の経緯 - yuji96&u=https://yuji96.github.io/posts/NLP2023-paper-history/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=卒研の経緯 - yuji96&url=https://yuji96.github.io/posts/NLP2023-paper-history/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recent Update</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/NLP2023-paper-history/">卒研の経緯</a><li><a href="/posts/first-OSS-1/">初めてOSS開発（IPython）にコミットした話 ①</a><li><a href="/posts/first-OSS-2/">初めてOSS開発（IPython）にコミットした話 ②</a><li><a href="/posts/cross-field/">分野横断すると見えてくるもの</a><li><a href="/posts/shinkan/">新歓ハンズオン資料編集後記</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ipython/">ipython</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/github/">github</a> <a class="post-tag" href="/tags/jupyter/">jupyter</a> <a class="post-tag" href="/tags/mac/">mac</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/sphinx/">sphinx</a> <a class="post-tag" href="/tags/dash/">dash</a> <a class="post-tag" href="/tags/for-beginner/">for-beginner</a> <a class="post-tag" href="/tags/labelimg/">labelImg</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/attention-for-me/"><div class="card-body"> <em class="timeago small" date="2023-02-17 00:00:00 +0900" >Feb 17</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>自分なりの Self Attention の解釈</h3><div class="text-muted small"><p> WIP ポエム せっかくルールが存在しない個人サイトなので、たまにはブログのような話から入ってみます。 卒論第一稿を書き終えて、久しぶりに何も無い日を 2 日くらい過ごせたので、結構メンタルが回復した気がします。 しかし自分にはやらなければならないことがどうやら 2 つあるようです。 それは呼吸器内科に行くことと歯科に行くことです。 さっき「あるようです」と語尾をぼか...</p></div></div></a></div><div class="card"> <a href="/posts/pyenv/"><div class="card-body"> <em class="timeago small" date="2021-12-18 19:34:00 +0900" >Dec 18, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>初心者がPythonのインストールでやりがちなこと</h3><div class="text-muted small"><p> 仮想環境という概念を知ろう 前提: brew がインストール済みの MacOS ちょっとしたエピソード 身の回りでこんな現象をよく聞く。 登場人物 A さん：プログラミングを始めたてで日々精進している。 B さん：大学の授業以外ではプログラミングは一切しない。 C 先生：ごく一般的な大学の先生。 A ...</p></div></div></a></div><div class="card"> <a href="/posts/relative-file/"><div class="card-body"> <em class="timeago small" date="2022-02-07 00:00:00 +0900" >Feb 7, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Python でファイルを相対的に読み込む方法</h3><div class="text-muted small"><p> こちらの記事と同じ内容です。 https://blog.shinonome.io/python-importfile/ こんにちは。今まで、C++, JavaScript, R などの言語に触れたことはありますが、結局 Python に返ってきてしまう Yuji です。 やりたいこと 今回の目標は、以下のような階層構造があったときに、reader.py から data.csv ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/attention-for-me/" class="btn btn-outline-primary" prompt="Older"><p>自分なりの Self Attention の解釈</p></a> <span class="btn btn-outline-primary disabled" prompt="Newer"><p>-</p></span></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ipython/">ipython</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/github/">github</a> <a class="post-tag" href="/tags/jupyter/">jupyter</a> <a class="post-tag" href="/tags/mac/">mac</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/sphinx/">sphinx</a> <a class="post-tag" href="/tags/dash/">dash</a> <a class="post-tag" href="/tags/for-beginner/">for-beginner</a> <a class="post-tag" href="/tags/labelimg/">labelImg</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
